{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "import copy\n",
    "import pandas\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import *\n",
    "\n",
    "import pickle\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for b in range(1, 6):\n",
    "    D = unpickle('./cifar-10-batches-py/data_batch_%s' % b)\n",
    "    X.append( D[b'data'].reshape((-1, 3, 32, 32)).astype('uint8') )\n",
    "    Y.append( np.array(D[b'labels']))\n",
    "    names = [x.decode('utf-8') for x in D]\n",
    "\n",
    "X = np.vstack(X)\n",
    "Y = np.hstack(Y).astype('int')\n",
    "\n",
    "D = unpickle('./cifar-10-batches-py/test_batch')\n",
    "Xt = D[b'data'].reshape((-1, 3, 32, 32)).astype('uint8')\n",
    "Yt = np.array(D[b'labels']).astype('int')\n",
    "Lt = D[b'filenames']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data\n",
    "==="
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "norm = Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "to_img = ToPILImage()\n",
    "resized_crop = RandomResizedCrop(32)\n",
    "crop = RandomCrop([32,32])\n",
    "central_crop = CenterCrop([32,32])\n",
    "flip = RandomHorizontalFlip()\n",
    "color = ColorJitter(brightness=0.5,contrast=0,saturation=0)\n",
    "gray = Grayscale()\n",
    "to_tensor = ToTensor()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "Xa = []\n",
    "Ya = []\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    x = X[i]\n",
    "    x = torch.from_numpy(x)\n",
    "    x = to_tensor((to_img(x))).numpy()\n",
    "    x = ((x - x.mean()) / (2*x.std())) + 0.5\n",
    "    Xa.append(x.tolist())\n",
    "    Ya.append(Y[i].tolist())\n",
    "\n",
    "    continue\n",
    "    \n",
    "    v = torch.from_numpy(x)\n",
    "    v = to_tensor(flip(to_img(v))).numpy()\n",
    "    if np.array_equal(v, x): continue\n",
    "    v = torch.from_numpy(x)\n",
    "    v = to_tensor(flip((central_crop(crop(to_img(v)))))).numpy()\n",
    "    Xa.append(v.tolist())\n",
    "    Ya.append(Y[i].tolist())\n",
    "\n",
    "Xa = np.array(Xa)\n",
    "Ya = np.array(Ya)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "Xta = []\n",
    "Yta = []\n",
    "for i in range(Xt.shape[0]):\n",
    "    x = Xt[i]\n",
    "    x = torch.from_numpy(x)\n",
    "    x = norm(to_tensor((to_img(x)))).numpy()\n",
    "    x = ((x - x.mean()) / (2*x.std())) + 0.5\n",
    "    Xta.append(x.tolist())\n",
    "    Yta.append(Y[i].tolist())\n",
    "Xta = np.array(Xta)\n",
    "Yta = np.array(Yta)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X.shape, Y.shape\n",
    "Xa.mean(), Xta[0].mean()\n",
    "Xa.std(), Xta[0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):  \n",
    "    def __init__(self,batch_size = 10, drop_probability = 0.5):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, 5, padding=1)\n",
    "        self.drop = nn.Dropout2d(drop_probability)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 5, padding=1)\n",
    "        self.drop = nn.Dropout2d(drop_probability)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(6 * 6 * 128, 6 * 6 * 100)\n",
    "        self.fc2 = nn.Linear(6 * 6 * 100, 6 * 6 * 50)\n",
    "        self.fc3 = nn.Linear(6 * 6 * 50, batch_size)\n",
    "        \n",
    "        self.train_epoch_loss_list = []\n",
    "        self.test_epoch_loss_list = []\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.pool(F.relu(self.bn1(self.drop(self.conv1(x))))) \n",
    "        x = self.pool(F.relu(self.bn2(self.drop(self.conv2(x))))) \n",
    "        x = x.view(-1, 128 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "batch_size = 2000\n",
    "drop_probability = 0.3\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net (\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "  (drop): Dropout2d (p=0.3)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (pool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (fc1): Linear (4608 -> 3600)\n",
       "  (fc2): Linear (3600 -> 1800)\n",
       "  (fc3): Linear (1800 -> 2000)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(batch_size=batch_size, drop_probability=drop_probability).cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49999999948210216"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xta.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 1/25 [00:01<00:42,  1.79s/it]\u001b[A\n",
      "  8%|▊         | 2/25 [00:03<00:40,  1.78s/it]\u001b[A\n",
      " 12%|█▏        | 3/25 [00:05<00:39,  1.80s/it]Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/usr/lib/python3.5/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 25/25 [00:44<00:00,  1.80s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 51.29652976989746 \n",
      "test: 14.769286870956421\n",
      "\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:45<00:00,  1.82s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 46.78963840007782 \n",
      "test: 15.463582992553711\n",
      "\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:44<00:00,  1.78s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 41.680458188056946 \n",
      "test: 15.171037435531616\n",
      "\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:44<00:00,  1.79s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 37.88062405586243 \n",
      "test: 16.82156252861023\n",
      "\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:44<00:00,  1.79s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 35.375502943992615 \n",
      "test: 19.164653301239014\n",
      "\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:45<00:00,  1.80s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 33.19261157512665 \n",
      "test: 20.817952632904053\n",
      "\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:46<00:00,  1.85s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 31.368825554847717 \n",
      "test: 21.40731954574585\n",
      "\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:44<00:00,  1.79s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 29.280216217041016 \n",
      "test: 21.747693061828613\n",
      "\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:46<00:00,  1.85s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 28.14022982120514 \n",
      "test: 23.266589164733887\n",
      "\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:46<00:00,  1.85s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 26.745235204696655 \n",
      "test: 24.989482879638672\n",
      "\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:45<00:00,  1.81s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 25.995025634765625 \n",
      "test: 24.941579818725586\n",
      "\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:46<00:00,  1.85s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 25.05539083480835 \n",
      "test: 25.607254028320312\n",
      "\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:46<00:00,  1.85s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 24.25772750377655 \n",
      "test: 25.946178436279297\n",
      "\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:48<00:00,  1.93s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 23.64755529165268 \n",
      "test: 27.471170902252197\n",
      "\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:45<00:00,  1.83s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 22.74498289823532 \n",
      "test: 28.091031551361084\n",
      "\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:46<00:00,  1.84s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 22.148992776870728 \n",
      "test: 28.40874195098877\n",
      "\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [00:15<00:39,  2.20s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_epoch_loss_list = []\n",
    "test_epoch_loss_list = []\n",
    "for epoch in range(n_epoch):\n",
    "    train_epoch_loss = 0\n",
    "    test_epoch_loss = 0\n",
    "    \n",
    "    print ('\\nEpoch %s/%s' %(epoch+1,n_epoch))\n",
    "    Xperm = np.random.permutation(Xa.shape[0])\n",
    "    net.train(True)\n",
    "    for b in tqdm(range(Xa.shape[0]//batch_size)):\n",
    "        batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "        \n",
    "        x = Variable(torch.Tensor(Xa[batch_idxs].tolist())).cuda()\n",
    "        y = Variable(torch.LongTensor(Ya[batch_idxs].tolist())).cuda()\n",
    "        \n",
    "        y_hat = net(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.data[0]\n",
    "\n",
    "    ## learn test\n",
    "    Xperm = np.random.permutation(Xta.shape[0])\n",
    "    net.train(False)\n",
    "    for b in range(Xta.shape[0]//batch_size):\n",
    "        batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "        x = Variable(torch.Tensor(Xta[batch_idxs].tolist()),volatile = True).cuda()\n",
    "        y = Variable(torch.LongTensor(Yta[batch_idxs]),volatile = True).cuda()\n",
    "\n",
    "        y_hat = net(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        test_epoch_loss += loss.data[0]\n",
    "    \n",
    "    # save loss and lr for current epoch\n",
    "    train_epoch_loss_list.append(train_epoch_loss)\n",
    "    test_epoch_loss_list.append(test_epoch_loss)\n",
    "    print (\"Epoch loss: \\ntrain: %s \\ntest: %s\\n\" %(train_epoch_loss_list[-1], test_epoch_loss_list[-1]))\n",
    "    \n",
    "net.train_epoch_loss_list = train_epoch_loss_list\n",
    "net.test_epoch_loss_list = test_epoch_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:48<00:00,  1.95s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: \n",
      "train: 80.64137864112854 \n",
      "test: 10.696401596069336\n",
      "\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [00:12<00:32,  1.80s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_epoch_loss_list = []\n",
    "test_epoch_loss_list = []\n",
    "for epoch in range(n_epoch):\n",
    "    train_epoch_loss = 0\n",
    "    test_epoch_loss = 0\n",
    "    \n",
    "    print ('\\nEpoch %s/%s' %(epoch+1,n_epoch))\n",
    "    Xperm = np.random.permutation(X.shape[0])\n",
    "    net.train(True)\n",
    "    for b in tqdm(range(X.shape[0]//batch_size)):\n",
    "        batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "        \n",
    "        x = Variable(torch.Tensor(X[batch_idxs].tolist())).cuda()\n",
    "        y = Variable(torch.LongTensor(Y[batch_idxs].tolist())).cuda()\n",
    "        \n",
    "        y_hat = net(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.data[0]\n",
    "\n",
    "    ## learn test\n",
    "    Xperm = np.random.permutation(Xt.shape[0])\n",
    "    net.train(False)\n",
    "    for b in range(Xt.shape[0]//batch_size):\n",
    "        batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "        x = Variable(torch.Tensor(Xt[batch_idxs].tolist()),volatile = True).cuda()\n",
    "        y = Variable(torch.LongTensor(Yt[batch_idxs]),volatile = True).cuda()\n",
    "\n",
    "        y_hat = net(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        test_epoch_loss += loss.data[0]\n",
    "    \n",
    "    # save loss and lr for current epoch\n",
    "    train_epoch_loss_list.append(train_epoch_loss)\n",
    "    test_epoch_loss_list.append(test_epoch_loss)\n",
    "    print (\"Epoch loss: \\ntrain: %s \\ntest: %s\\n\" %(train_epoch_loss_list[-1], test_epoch_loss_list[-1]))\n",
    "    \n",
    "net.train_epoch_loss_list = train_epoch_loss_list\n",
    "net.test_epoch_loss_list = test_epoch_loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min values and epoch\n",
      "train: 30.51696527\n",
      "test: 5.97973895073\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncQp6ERGP+/98K9GTad943gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f257b2438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\"Min values and epoch\\ntrain: %s\\ntest: %s\" \\\n",
    "       %(np.array(train_epoch_loss_list).min(), np.array(test_epoch_loss_list).min()) )\n",
    "train_loss, = plt.plot(train_epoch_loss_list, 'g-',linewidth = 1, label='Train')\n",
    "test_loss, = plt.plot(test_epoch_loss_list, 'b-',linewidth = 1, label = \"Test\")\n",
    "plt.legend(handles=[train_loss, test_loss])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save parameters to pickle file\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_parametrs = net.state_dict()\n",
    "with open('./result_nets.pkl','wb') as f:\n",
    "    pickle.dump(net_parametrs,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load parameters from pickle file\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./result_nets.pkl','rb') as f:\n",
    "    result_nets = pickle.load(f)\n",
    "net.load_state_dict(result_nets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn test data\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.train(False)\n",
    "\n",
    "batch_size = 1000\n",
    "loss_acc = 0\n",
    "Xperm = np.random.permutation(Xt.shape[0])\n",
    "loss_fn = torch.nn.CrossEntropyLoss().cuda()\n",
    "y_hat = []\n",
    "for b in range(Xt.shape[0]//batch_size):\n",
    "    batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "    x = Variable(torch.Tensor(Xt[batch_idxs].tolist()),volatile = True).cuda()\n",
    "    y = Variable(torch.LongTensor(Yt[batch_idxs]),volatile = True).cuda()\n",
    "    \n",
    "    \n",
    "    y_hat.append(net(x))\n",
    "    loss = loss_fn(y_hat[b], y)\n",
    "    loss_acc +=loss.data[0]\n",
    "\n",
    "print (loss_acc / (Xt.shape[0]//batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save result of test\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pandas.DataFrame()\n",
    "d['id'] = range(len(Yt))\n",
    "res = y_hat\n",
    "if type(y_hat) == list:\n",
    "    res = y_hat[0].data.cpu().numpy()\n",
    "    for i in range(1, len(y_hat)):\n",
    "        res = np.vstack((res, y_hat[i].cpu().data.numpy()))\n",
    "        \n",
    "for i in range(10):\n",
    "    d['c%s' % i] = np.exp(res[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.to_csv('./ground.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classes:**\n",
    "======\n",
    "1. airplane \n",
    "2. automobile\n",
    "3. bird\n",
    "4. cat\n",
    "5. deer \n",
    "6. dog\n",
    "7. frog\n",
    "8. horse\n",
    "9. ship\n",
    "10. truck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "    def __init__(self):\n",
    "        self.lr0 = 0.0001\n",
    "        self.epoch = 0\n",
    "        self.punch = 0.0003\n",
    "        self.lr = 0.0001\n",
    "        self.base = 0.5\n",
    "    \n",
    "    @property\n",
    "    def rate(self):\n",
    "        return self.epoch // 15\n",
    "    \n",
    "    def make_punch(self):\n",
    "        self.lr = self.punch\n",
    "        self.epoch = 0\n",
    "        \n",
    "    @property\n",
    "    def updated_lr(self):\n",
    "        return self.lr0 * ( self.base **  self.rate )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
