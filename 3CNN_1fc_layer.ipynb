{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Best loss = 0.60***\n",
    "\n",
    "Activation function was ReLU\n",
    "\n",
    "epoch=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import optim\n",
    "# cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=1000\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32),\n",
    "            transforms.CenterCrop(32),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=False),\n",
    "        batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a model**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.feature_map_size = 4 * 4 * 256\n",
    "        \n",
    "        self.c1_layer = nn.Sequential( \\\n",
    "                                        nn.BatchNorm2d(3),\n",
    "                                        nn.Conv2d(3,64,3,padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(64,64,3,padding=1),\n",
    "                                        nn.MaxPool2d(2,stride=2),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout2d(0.25)\n",
    "                                       )\n",
    "        self.c2_layer = nn.Sequential( \\\n",
    "                                        nn.Conv2d(64,128,3,padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(128,128,3,padding=1),\n",
    "                                        nn.MaxPool2d(2,stride=2),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout2d(0.25)\n",
    "                                       )\n",
    "        self.c3_layer = nn.Sequential( \\\n",
    "                                        nn.Conv2d(128,256,3,padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(256,256,3,padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(256,256,3,padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(256,256,3,padding=1),\n",
    "                                        nn.MaxPool2d(2,stride=2),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout2d(0.25)\n",
    "                                     )\n",
    "                                      \n",
    "        self.fc_layer = nn.Sequential( \\\n",
    "                                        nn.Linear(self.feature_map_size, 1024),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout2d(),\n",
    "                                        nn.Linear(1024, 1024),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout2d(),\n",
    "                                        nn.Linear(1024, 10)\n",
    "                                    )\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.c1_layer(x)\n",
    "        x = self.c2_layer(x)\n",
    "        x = self.c3_layer(x)\n",
    "        x = x.view(-1, self.feature_map_size)  \n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learn the model**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Combination of augmented data and raw data'''\n",
    "def run(s_epoch,n_epoch,lr):\n",
    "    net.train(True)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "#     for epoch in tqdm(range(s_epoch,n_epoch)):  \n",
    "    for epoch in range(s_epoch,n_epoch):  \n",
    "        running_corrects= 0\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            \n",
    "        print(\"Train accuracy %s and loss %s\\n\" %(running_corrects/len(trainloader.dataset),running_loss))\n",
    "        loss_data.append(running_loss)\n",
    "        corrects.append(running_corrects/len(trainloader.dataset))\n",
    "    print('Finished Training')\n",
    "    print(\"Train accuracy %s and loss %s\\n\" %(running_corrects/len(trainloader.dataset),running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_data = []\n",
    "corrects = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.18116 and loss 107.5786726474762\n",
      "\n",
      "Train accuracy 0.31174 and loss 90.65355718135834\n",
      "\n",
      "Train accuracy 0.40724 and loss 78.85357797145844\n",
      "\n",
      "Train accuracy 0.49616 and loss 68.52150189876556\n",
      "\n",
      "Train accuracy 0.55456 and loss 61.00254583358765\n",
      "\n",
      "Train accuracy 0.59486 and loss 56.40764844417572\n",
      "\n",
      "Train accuracy 0.6306 and loss 51.73451954126358\n",
      "\n",
      "Train accuracy 0.65998 and loss 47.95654225349426\n",
      "\n",
      "Train accuracy 0.68088 and loss 45.1919219493866\n",
      "\n",
      "Train accuracy 0.70182 and loss 42.50929868221283\n",
      "\n",
      "Train accuracy 0.71902 and loss 40.12581664323807\n",
      "\n",
      "Train accuracy 0.7328 and loss 38.2113271355629\n",
      "\n",
      "Train accuracy 0.75052 and loss 35.92939764261246\n",
      "\n",
      "Train accuracy 0.76322 and loss 34.39856493473053\n",
      "\n",
      "Train accuracy 0.7725 and loss 32.9351886510849\n",
      "\n",
      "Train accuracy 0.77818 and loss 32.045094549655914\n",
      "\n",
      "Train accuracy 0.7927 and loss 30.102792620658875\n",
      "\n",
      "Train accuracy 0.79886 and loss 29.173475325107574\n",
      "\n",
      "Train accuracy 0.80582 and loss 28.037240087985992\n",
      "\n",
      "Train accuracy 0.8143 and loss 26.701633155345917\n",
      "\n",
      "Train accuracy 0.81924 and loss 26.071945399045944\n",
      "\n",
      "Train accuracy 0.82488 and loss 25.835509717464447\n",
      "\n",
      "Train accuracy 0.83314 and loss 24.296400368213654\n",
      "\n",
      "Train accuracy 0.83758 and loss 23.874015271663666\n",
      "\n",
      "Train accuracy 0.84042 and loss 23.013074725866318\n",
      "\n",
      "Train accuracy 0.84568 and loss 22.297001510858536\n",
      "\n",
      "Train accuracy 0.85028 and loss 21.69879049062729\n",
      "\n",
      "Train accuracy 0.85248 and loss 21.196154057979584\n",
      "\n",
      "Train accuracy 0.85904 and loss 20.343106359243393\n",
      "\n",
      "Train accuracy 0.86282 and loss 20.093517303466797\n",
      "\n",
      "Train accuracy 0.86648 and loss 19.33038055896759\n",
      "\n",
      "Train accuracy 0.87192 and loss 18.70869880914688\n",
      "\n",
      "Train accuracy 0.8753 and loss 18.179464906454086\n",
      "\n",
      "Train accuracy 0.8731 and loss 18.172251522541046\n",
      "\n",
      "Train accuracy 0.87888 and loss 17.39648449420929\n",
      "\n",
      "Train accuracy 0.88268 and loss 17.048864662647247\n",
      "\n",
      "Train accuracy 0.88424 and loss 16.876615911722183\n",
      "\n",
      "Train accuracy 0.8858 and loss 16.243703216314316\n",
      "\n",
      "Train accuracy 0.891 and loss 15.818220138549805\n",
      "\n",
      "Train accuracy 0.89438 and loss 15.247250035405159\n",
      "\n",
      "Finished Training\n",
      "Train accuracy 0.89438 and loss 15.247250035405159\n",
      "\n",
      "CPU times: user 13min 53s, sys: 1min 8s, total: 15min 2s\n",
      "Wall time: 15min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run(0,40,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.88798 and loss 16.123976856470108\n",
      "\n",
      "Train accuracy 0.89818 and loss 14.73160645365715\n",
      "\n",
      "Train accuracy 0.9001 and loss 14.681829139590263\n",
      "\n",
      "Train accuracy 0.90014 and loss 14.443586483597755\n",
      "\n",
      "Train accuracy 0.90662 and loss 13.504648625850677\n",
      "\n",
      "Train accuracy 0.90746 and loss 13.504818990826607\n",
      "\n",
      "Train accuracy 0.9085 and loss 13.350712656974792\n",
      "\n",
      "Train accuracy 0.9111 and loss 12.94841343164444\n",
      "\n",
      "Train accuracy 0.9112 and loss 12.866643026471138\n",
      "\n",
      "Train accuracy 0.91026 and loss 12.83768031001091\n",
      "\n",
      "Train accuracy 0.91396 and loss 12.377125278115273\n",
      "\n",
      "Train accuracy 0.91622 and loss 12.089767023921013\n",
      "\n",
      "Train accuracy 0.91942 and loss 11.70405949652195\n",
      "\n",
      "Train accuracy 0.92178 and loss 11.271068334579468\n",
      "\n",
      "Train accuracy 0.92306 and loss 11.082750484347343\n",
      "\n",
      "Train accuracy 0.92172 and loss 11.110503524541855\n",
      "\n",
      "Train accuracy 0.92228 and loss 11.190772637724876\n",
      "\n",
      "Train accuracy 0.9229 and loss 11.012647956609726\n",
      "\n",
      "Train accuracy 0.92766 and loss 10.285326853394508\n",
      "\n",
      "Train accuracy 0.92578 and loss 10.58633428812027\n",
      "\n",
      "Train accuracy 0.92402 and loss 10.756856083869934\n",
      "\n",
      "Train accuracy 0.92516 and loss 10.843367353081703\n",
      "\n",
      "Train accuracy 0.93058 and loss 9.894066229462624\n",
      "\n",
      "Train accuracy 0.93124 and loss 9.93218632042408\n",
      "\n",
      "Train accuracy 0.93236 and loss 9.993111178278923\n",
      "\n",
      "Train accuracy 0.9334 and loss 9.787237882614136\n",
      "\n",
      "Train accuracy 0.93392 and loss 9.715878829360008\n",
      "\n",
      "Train accuracy 0.93316 and loss 9.659555271267891\n",
      "\n",
      "Train accuracy 0.93702 and loss 9.14829395711422\n",
      "\n",
      "Train accuracy 0.93764 and loss 8.980562813580036\n",
      "\n",
      "Train accuracy 0.93734 and loss 9.05012620985508\n",
      "\n",
      "Train accuracy 0.9381 and loss 8.912223279476166\n",
      "\n",
      "Train accuracy 0.93962 and loss 8.6215211302042\n",
      "\n",
      "Train accuracy 0.9403 and loss 8.681926533579826\n",
      "\n",
      "Train accuracy 0.94028 and loss 8.704080045223236\n",
      "\n",
      "Train accuracy 0.94162 and loss 8.39379807561636\n",
      "\n",
      "Train accuracy 0.94208 and loss 8.502725437283516\n",
      "\n",
      "Train accuracy 0.94394 and loss 8.087054140865803\n",
      "\n",
      "Train accuracy 0.94476 and loss 8.142553135752678\n",
      "\n",
      "Train accuracy 0.94506 and loss 8.058544173836708\n",
      "\n",
      "Train accuracy 0.94402 and loss 8.06268186122179\n",
      "\n",
      "Train accuracy 0.94346 and loss 8.228032499551773\n",
      "\n",
      "Train accuracy 0.9462 and loss 7.798977427184582\n",
      "\n",
      "Train accuracy 0.9475 and loss 7.538073152303696\n",
      "\n",
      "Train accuracy 0.94788 and loss 7.434638790786266\n",
      "\n",
      "Train accuracy 0.9468 and loss 7.7659647688269615\n",
      "\n",
      "Train accuracy 0.94896 and loss 7.464750550687313\n",
      "\n",
      "Train accuracy 0.94746 and loss 7.607880346477032\n",
      "\n",
      "Train accuracy 0.95084 and loss 7.142069734632969\n",
      "\n",
      "Train accuracy 0.95024 and loss 7.318076558411121\n",
      "\n",
      "Train accuracy 0.95198 and loss 6.940181411802769\n",
      "\n",
      "Train accuracy 0.9495 and loss 7.289308495819569\n",
      "\n",
      "Train accuracy 0.9527 and loss 6.791744977235794\n",
      "\n",
      "Train accuracy 0.95494 and loss 6.712189182639122\n",
      "\n",
      "Train accuracy 0.95132 and loss 7.091269455850124\n",
      "\n",
      "Train accuracy 0.95374 and loss 6.828780263662338\n",
      "\n",
      "Train accuracy 0.95376 and loss 6.855350375175476\n",
      "\n",
      "Train accuracy 0.95486 and loss 6.530810669064522\n",
      "\n",
      "Train accuracy 0.95358 and loss 6.769376061856747\n",
      "\n",
      "Train accuracy 0.95526 and loss 6.755695432424545\n",
      "\n",
      "Finished Training\n",
      "Train accuracy 0.95526 and loss 6.755695432424545\n",
      "\n",
      "CPU times: user 20min 36s, sys: 1min 42s, total: 22min 19s\n",
      "Wall time: 22min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run(40,100,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9638 and loss 5.247608922421932\n",
      "\n",
      "Train accuracy 0.9695 and loss 4.555219724774361\n",
      "\n",
      "Train accuracy 0.97288 and loss 4.081075444817543\n",
      "\n",
      "Train accuracy 0.97296 and loss 4.021172821521759\n",
      "\n",
      "Train accuracy 0.9734 and loss 3.872068550437689\n",
      "\n",
      "Train accuracy 0.97636 and loss 3.4375724121928215\n",
      "\n",
      "Train accuracy 0.97742 and loss 3.354283470660448\n",
      "\n",
      "Train accuracy 0.97726 and loss 3.395396877080202\n",
      "\n",
      "Train accuracy 0.9761 and loss 3.4142263904213905\n",
      "\n",
      "Train accuracy 0.97806 and loss 3.2414479926228523\n",
      "\n",
      "Train accuracy 0.9778 and loss 3.2731963619589806\n",
      "\n",
      "Train accuracy 0.97956 and loss 2.957782367244363\n",
      "\n",
      "Train accuracy 0.97972 and loss 2.9968150556087494\n",
      "\n",
      "Train accuracy 0.98074 and loss 2.7638172693550587\n",
      "\n",
      "Train accuracy 0.98024 and loss 2.9096366316080093\n",
      "\n",
      "Train accuracy 0.98166 and loss 2.753248555585742\n",
      "\n",
      "Train accuracy 0.98056 and loss 2.8700411282479763\n",
      "\n",
      "Train accuracy 0.98112 and loss 2.8425263799726963\n",
      "\n",
      "Train accuracy 0.98164 and loss 2.764766402542591\n",
      "\n",
      "Train accuracy 0.98116 and loss 2.7700538858771324\n",
      "\n",
      "Train accuracy 0.98246 and loss 2.7233477495610714\n",
      "\n",
      "Train accuracy 0.98242 and loss 2.6423265263438225\n",
      "\n",
      "Train accuracy 0.98312 and loss 2.529664885252714\n",
      "\n",
      "Train accuracy 0.98234 and loss 2.609183706343174\n",
      "\n",
      "Train accuracy 0.9827 and loss 2.558399014174938\n",
      "\n",
      "Train accuracy 0.98378 and loss 2.3639258835464716\n",
      "\n",
      "Train accuracy 0.98428 and loss 2.3911262713372707\n",
      "\n",
      "Train accuracy 0.98304 and loss 2.4807093255221844\n",
      "\n",
      "Train accuracy 0.9833 and loss 2.448578292503953\n",
      "\n",
      "Train accuracy 0.98408 and loss 2.3385595455765724\n",
      "\n",
      "Train accuracy 0.9843 and loss 2.27188834361732\n",
      "\n",
      "Train accuracy 0.9843 and loss 2.307145854458213\n",
      "\n",
      "Train accuracy 0.98398 and loss 2.328157965093851\n",
      "\n",
      "Train accuracy 0.98496 and loss 2.2210906855762005\n",
      "\n",
      "Train accuracy 0.98478 and loss 2.2477108370512724\n",
      "\n",
      "Train accuracy 0.98418 and loss 2.279405627399683\n",
      "\n",
      "Train accuracy 0.98512 and loss 2.179419308900833\n",
      "\n",
      "Train accuracy 0.9857 and loss 2.1713603269308805\n",
      "\n",
      "Train accuracy 0.98592 and loss 2.1328255105763674\n",
      "\n",
      "Train accuracy 0.98558 and loss 2.1376297511160374\n",
      "\n",
      "Finished Training\n",
      "Train accuracy 0.98558 and loss 2.1376297511160374\n",
      "\n",
      "CPU times: user 13min 45s, sys: 1min 7s, total: 14min 52s\n",
      "Wall time: 14min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run(100,250,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f217ddab4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_data[-30:])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eval the model**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net (\n",
       "  (c1_layer): Sequential (\n",
       "    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU ()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (5): ReLU ()\n",
       "    (6): Dropout2d (p=0.25)\n",
       "  )\n",
       "  (c2_layer): Sequential (\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU ()\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (4): ReLU ()\n",
       "    (5): Dropout2d (p=0.25)\n",
       "  )\n",
       "  (c3_layer): Sequential (\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU ()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU ()\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU ()\n",
       "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (8): ReLU ()\n",
       "    (9): Dropout2d (p=0.25)\n",
       "  )\n",
       "  (fc_layer): Sequential (\n",
       "    (0): Linear (4096 -> 1024)\n",
       "    (1): ReLU ()\n",
       "    (2): Dropout2d (p=0.5)\n",
       "    (3): Linear (1024 -> 1024)\n",
       "    (4): ReLU ()\n",
       "    (5): Dropout2d (p=0.5)\n",
       "    (6): Linear (1024 -> 10)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.8674 and loss 6.838100969791412\n",
      "\n",
      "Accuracy of plane : 87 %\n",
      "Accuracy of   car : 93 %\n",
      "Accuracy of  bird : 81 %\n",
      "Accuracy of   cat : 71 %\n",
      "Accuracy of  deer : 87 %\n",
      "Accuracy of   dog : 80 %\n",
      "Accuracy of  frog : 91 %\n",
      "Accuracy of horse : 90 %\n",
      "Accuracy of  ship : 92 %\n",
      "Accuracy of truck : 92 %\n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "running_corrects=0\n",
    "running_loss=0\n",
    "y_hat = []\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "    outputs = net(Variable(images, volatile=True))\n",
    "    \n",
    "    loss = criterion(outputs, Variable(labels, volatile=True))\n",
    "    running_loss += loss.data[0]\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    running_corrects += torch.sum(preds == labels)\n",
    "    \n",
    "    y_hat.append(outputs)\n",
    "        \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(1000):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1 \n",
    "print (\"test accuracy %s and loss %s\\n\" %(running_corrects/10000,running_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3CNN_1fc_layer.ipynb\n",
      "92perc_2cnn.pkl\n",
      "92perc_3cnn.pkl\n",
      "README.md\n",
      "cnn_88perc_test.ipynb\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm *.csv\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "d = pandas.DataFrame()\n",
    "d['id'] = range(10000)\n",
    "res = y_hat\n",
    "res = y_hat[0].data.cpu().numpy()\n",
    "for i in range(1, 10):\n",
    "    res = np.vstack((res, y_hat[i].cpu().data.numpy()))\n",
    "        \n",
    "for i in range(10):\n",
    "    res = np.array(res, dtype=np.float128)\n",
    "    d['c%s' % i] = np.exp(res[:, i])\n",
    "d.to_csv('./ground1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Save parametrs to pickle**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_parametrs = net.state_dict()\n",
    "with open('./92perc_3cnn.pkl','wb') as f:\n",
    "    pickle.dump(net_parametrs,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./92perc_3cnn.pkl','rb') as f:\n",
    "    result_nets = pickle.load(f)\n",
    "net.load_state_dict(result_nets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
