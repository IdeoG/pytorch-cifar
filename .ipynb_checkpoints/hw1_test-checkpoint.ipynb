{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "import copy\n",
    "import pandas\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import *\n",
    "import torchvision\n",
    "import pickle\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for b in range(1, 6):\n",
    "    D = unpickle('./cifar-10-batches-py/data_batch_%s' % b)\n",
    "    X.append( D[b'data'].reshape((-1, 3, 32, 32)).astype('uint8') )\n",
    "    Y.append( np.array(D[b'labels']))\n",
    "    names = [x.decode('utf-8') for x in D]\n",
    "\n",
    "X = np.vstack(X)\n",
    "Y = np.hstack(Y).astype('int')\n",
    "\n",
    "D = unpickle('./cifar-10-batches-py/test_batch')\n",
    "Xt = D[b'data'].reshape((-1, 3, 32, 32)).astype('uint8')\n",
    "Yt = np.array(D[b'labels']).astype('int')\n",
    "Lt = D[b'filenames']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_img = ToPILImage()\n",
    "resized_crop = RandomResizedCrop(32)\n",
    "crop = RandomCrop([32,32])\n",
    "central_crop = CenterCrop([32,32])\n",
    "flip = RandomHorizontalFlip()\n",
    "color = ColorJitter(brightness=0.5,contrast=0,saturation=0)\n",
    "gray = Grayscale()\n",
    "to_tensor = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X[0]\n",
    "x = torch.from_numpy(x)\n",
    "x = to_tensor(to_img(x)).numpy()\n",
    "v = torch.from_numpy(x)\n",
    "v = color(to_img(v))\n",
    "v = to_tensor(v).numpy()\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show image\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa1bd3c2470>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfiESRc4vRKLI+YVIlP8Dfw9Sr1G8vSsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1bd50ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.rot90(x.T, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa1b20ed630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAH3NJREFUeJztnWuMnNd53//P3Gd29r68aUmLFEVZ\nViRbUlhFhd3AiRFXMYxKLgrD/uCqgBEFRQzUgPtBcIHaBfrBKWob/tC6pWshSuH60tiGhcBooqgB\n1DSubOpi3SiTIkXxttwld5d737k+/TDDgKLP/+yIS85KOf8fQHD2PHPmPe+Z88w7c/7v8zzm7hBC\npEdmqwcghNga5PxCJIqcX4hEkfMLkShyfiESRc4vRKLI+YVIFDm/EIki5xciUXKb6WxmDwD4BoAs\ngP/m7l+JPb9aKfnY8OC1HIdY+N2JrAcAZOjrAW1vc1s7bGu3W7RP/AbKyPgzsTPgtlYrPJaMxT7n\n+et5ZD4s8poZMn6/hrF3jkVNyGUjy5i8AbHz8sj70mzyfs0Wt9Vj/cjhYmsnmwufc219HY1GI7Z4\n/o5rdn4zywL4TwB+D8AZAL8wsyfc/VXWZ2x4EF/4Fw8FbVnjZ1ooFsKGdpOPL/LmltnrAWg01qlt\nZWUl2L68skz7tCILooUGtRWKeWrrfNaGWVhYCrZXygORV+Ovt75Wo7ZSqUhtxWLY1s7w85pfWKC2\nQo6v57GREWpDK7xGmvU12qXe4u/LxUvhNQAAF+e57fTsKrXN1cPnVmvzD9eRkbFg+4svPE/7XM1m\nvvbfB+B1dz/h7nUA3wPw4CZeTwjRRzbj/JMATl/x95lumxDiXcAN3/Azs0fM7LCZHV5e5V+phRD9\nZTPOfxbAniv+3t1tewvufsjdD7r7wWqltInDCSGuJ5tx/l8AOGBm+8ysAOBTAJ64PsMSQtxornm3\n392bZvY5AH+BzvbzY+7+SqxPvbaGc6+/FLS1mnxXOZcP7xBXSpEdcSLLAYBHdnO9zW2rq+Ed22yW\n75YXI8rCWpP/DKqT3XIAiCiLmJudC7YvZvg4ysUKH0e9Tm2tiNqSzYWvK7Um37Vvtrjik8/y69RC\niZ9bhdjM+XlZlo/Ranxdrc5coLb56bAKAwBvzobX/jx3CQyPjwfb19e4inE1m9L53f2nAH66mdcQ\nQmwNusNPiESR8wuRKHJ+IRJFzi9Eosj5hUiUTe32v13arRaWl8LBG5XIDUCNZlh+a7W5xFYd4PIV\nGwMAtCKfh/lKODgmFt1WqvKAGtT5OcfqKdRqXAMql4eD7cUCP1Y+xyXTgUgQZr3BZaVcPiyXzczx\nAJd8jo8xFtjTigRxLa2G56qU50u/XOTjKGf5+7J9Gx9Hw/kaaSO8HtsXI+8zmY+VWPjjVejKL0Si\nyPmFSBQ5vxCJIucXIlHk/EIkSl93+1vtNhZWwgEVAwM8OKOYIZ9RkcCY2jLfKc1Egn4QyZ1Xb4RV\nh2Jkd7gVCSIqRAKCGpEd/UyTB9RUS+Vg+ypJQQYAzUjOunIkeKpc5NeOwcGw2rKwwHf7W5GgqmpE\ndmjW+TpYIserLdIuqEWCY7IZvnZykXW1Y5DPYy43GmxfqfFAoaaF10Am8l7++nOFEEki5xciUeT8\nQiSKnF+IRJHzC5Eocn4hEqWvUl+j2ca5i2HpZXaBV72pVsLDHKlw+WR4gOfAy0RKRhUiAR8DpEJN\nIT9E+6xG5MjyQEQijMhXsZJiq7Vwgr+688R/y2tc96rUuARbLYdlRQBYWw/Lds0GlynbkepGOY8E\nSJHSVR1b+L0uFXifQiyHXyTgKluIBJpFJNNmJjwn26p8Da8R152Olnl7K7ryC5Eocn4hEkXOL0Si\nyPmFSBQ5vxCJIucXIlE2JfWZ2UkASwBaAJrufjD2/Fq9iRNnwpFK2RaXom7eHZbSrMWlplwkr14s\nv195MFwGCQByHh7H9DQv/XT64mlqKw/z8eedS2KLq9zWaIej94aKPGIulgNvFZEIyFakXJeHoxI9\nokR5i89jfZ1LwW5cRrN2WJrL5yKRjBEZMBPL8ZjjUl+tzqM0S6Vwv50TPJJxuRE+5+MzvUt910Pn\n/x13v3gdXkcI0Uf0tV+IRNms8zuAvzSzZ83skesxICFEf9js1/4PuftZM9sO4Ekze83dn77yCd0P\nhUcAIHLXpBCiz2zqyu/uZ7v/zwD4MYD7As855O4H3f2gnF+Idw7X7PxmNmBmg5cfA/gogJev18CE\nEDeWzXzt3wHgx9YpD5QD8D/c/X/FOhSKeezbtzNo2z7EI5hYnkiPRMxZ5HOtXOSnPVTmstEK0TRy\ndT72D9x2F7X97Mhz1La4tERtjYheVrSwZLp9jI+RVEMDAJxb5Qk36xluGyiGxzG5bYL2GRrk0pa1\nuaw4PBwuUQYAeSL51td5JGNtjctyFZIgtQNfcxHlGdWB8JqbtCrts9gIy4OFN3q/nl+z87v7CQAf\nuNb+QoitRVKfEIki5xciUeT8QiSKnF+IRJHzC5EofU3gWcpnsX8yLMvsGOUyz/mpqWB7rsBluXyB\nf66VIskU0eLyYbMRruG2tsy1MrvEJbZchkeWWaTmWiXLx/9b+yeD7f/03n20z9nzvI7ff37yWd5v\njUdiVnJhaa62skD77L+ZR1TumuAJPBsN/p7lsuF1UBniSVe78nWQlYgMaBF3qgxGJMJaOJqxabxm\n4Gg1LANmWV3LALryC5Eocn4hEkXOL0SiyPmFSBQ5vxCJ0tfd/kIug5snwvnz1iIlo0ZHwjulpchu\nfyZStqid4ae9UOM5684uzQTb37zIx+7zkc/XyOxXczzP4I6RbdR269D2YHtpfo722ZbjufMGi3w+\nsm1+Ak6uK3NLXCHInOFj3L5jL7UVCvy9vjQffm88UpYtkrUQTeN5+tZrPPiozMUb5Ei5sXKBK0Xl\nsbAywl4rhK78QiSKnF+IRJHzC5Eocn4hEkXOL0SiyPmFSJS+Sn0A4K2w5sEFFGCwEpb6YsmALSLY\nWCOStC4iydSbYSnHIwE6A5F4jkohUq4rx2We8ZEStV1cCefVe2pqmvbJFrhENTrEA2puGeDLZ52M\nY73Bj7VS5wFGr70RllkB4H23HqC26mgh2F6v82Agj4wxk+PXy1yWr+LqAM/HNzw4Emxve2SdFsOv\nJ6lPCLEhcn4hEkXOL0SiyPmFSBQ5vxCJIucXIlE21AXM7DEAHwcw4+53dtvGAHwfwF4AJwF80t3n\nNz6cwUjdokxEuMtlwhJKJpKvrFHnkWqNSJmvXJbLPMVcOH/b5A4eXfjeAzdR2949B6ntxOunqK1e\n49FvrVY4R95iRHIcGuQltPYPcrlpX5FLjkdPnAu2r6/wMmTFEn+9+Yt8ea3wKcbEzvC5WSSKNB+5\nJrbbXEJuRuTlYixvJFEIDbyPZ5it92q4vVz5/wTAA1e1PQrgKXc/AOCp7t9CiHcRGzq/uz8N4OpL\nzYMAHu8+fhzAQ9d5XEKIG8y1/ubf4e6X82mfR6dirxDiXcSmN/zc3RG5KdbMHjGzw2Z2eGU9crui\nEKKvXKvzT5vZLgDo/k9vvHb3Q+5+0N0PDsQ2PYQQfeVanf8JAA93Hz8M4CfXZzhCiH7Ri9T3XQAf\nBjBhZmcAfAnAVwD8wMw+C+BNAJ/s7XCOzq+EXyeSbxMtFmWVD0dsATEpBChEJKWs8XJMaIZltO0j\nvNTYXe+/ndomJsLRXAAwPsHP7Y2jr1HbSGVnsP3M9HnapzrGx5FduEBto0M8Um3XzruC7eeOHaZ9\nKiUeHXliiif+9CaXD1fWw9e3c2f5fAyW+ftZrfDEqu02XzvLLV56y42ddyRBaisc9dkm/vX2Xv3y\nQdw/TUwf6fkoQoh3HLrDT4hEkfMLkShyfiESRc4vRKLI+YVIlP4m8IzcC5iLROi5hXXASIAVPHJq\ntSbXFa3JpZLhwbC0lc9z+efsFI/A80iNvIESD8Pbszdcpw0Atk+EQ9z23L6X9mlneCTjpYVdkWOF\n6wICwMXZcMLQ4eIo7XPLTWPUtv7kr6jt9ak3qW21FY7qW1jikZ2zc1yyu3Xve6jtpm383FqNcEJT\nAKiTNWfG3xfLh6VPj2WgvQpd+YVIFDm/EIki5xciUeT8QiSKnF+IRJHzC5EofZX6LGPIF8LRdu11\nLr0USaLIlTqXQhptLnmUCjxiLp/jtj3vCdeEGxwPR9IBwNBOHiE2UOTjr0TCHEdHIgkms+GEKaMV\nXvsvCz7GocnbqG18J8+cefFnfxFszw/xCMLhm/ZS202TPCruVCRicepk2NbK86jP9XWuIZ86fYba\nBrJc+hyo8HWVIdGpAwP8PctVw7JzNlIv8NeO2/MzhRB/r5DzC5Eocn4hEkXOL0SiyPmFSJS+7va3\n3bHeCO9GtyOfQy22cZ/lw89m+evVa3zneNtuXrrqHzzw8WB7eYQHvzTavMzUcJYHkKzO8X4ZopgA\nwND2cHBMi5RJA4BCYRu1tcEDjObOTVFbNRcOcnn5OA9mygwMU9tNd/4jats29b+pbeV0OLCqHMm7\neGkl8r4sh/M4AkAuy9dBLrYJb+E5aa5xBWy9GQ7sabe4gnQ1uvILkShyfiESRc4vRKLI+YVIFDm/\nEIki5xciUXop1/UYgI8DmHH3O7ttXwbwBwAu13L6orv/dKPXcgfqzXDQRAZcolivr4Rfz7h+woIl\nAMALXELJDFETdt0aDnIpV/fRPrPTPL/c7IXXqW1olOeKK5R5zsAcCZwZGuNBJzBedmt9dpbazr7x\nf6mtUg/P8UiOH+vFXxyntof++cPUdrDBA3Eu/SQcYHR+jleMvlDjQWFUdgbQMr6u0ODlxtqNsBvG\n8vFlC+F5jFS9+zV6ufL/CYAHAu1fd/e7u/82dHwhxDuLDZ3f3Z8GwFPQCiHelWzmN//nzOxFM3vM\nzHjOYiHEO5Jrdf5vAtgP4G4AUwC+yp5oZo+Y2WEzO7xa6/3WQyHEjeWanN/dp9295e5tAN8CcF/k\nuYfc/aC7H6wU+1sjRAjBuSbnN7MrIxg+AeDl6zMcIUS/6EXq+y6ADwOYMLMzAL4E4MNmdjc6xbdO\nAvjDXg7WbrewWl8M2oqDPNJueCIc7ZUrcjkvW+CnlmkPUFuk8hYWly8E28tVHhU3c/5VavvZzw9T\n252/cS+17d8ficJbC593fZb/5CpEyoa113m/ndt4BOSlU+HcefsmI31ePUtti+vL1Hb7/fSLJ2an\nwvLh889xmbW5ytfV7Cwvu+VrXD7MViNRq+3wHLcj9eiyvVflomzo/O7+6UDztzd/aCHEVqI7/IRI\nFDm/EIki5xciUeT8QiSKnF+IROnrXTfZPDA0EY47GhrhSSmzuXC0VL3G5Z/WOo9vylq4/BcAeIHL\ngK3V8PFmZ07QPmemfkltE+P8nBurPFHkC3/7NLVliVY5smOS9tmxaze1lQp8HsvjO6gtXw7PcWOc\nz9WeRS6jnTpxhNre90Ee8ff+D4aTjM5d4hF4zVPT1DaS5+XGshm+dtqRMnDNZlgirK+FZXEAyLXC\nUYLuvWuAuvILkShyfiESRc4vRKLI+YVIFDm/EIki5xciUfoq9eXyWWzfFa6RtjRzjvZbmA0n8MwS\nuQMAcjwgCs1I4bTxMo86qxZILbksrzG39z13UVuuxaWtN4+dorbzJ3n0W41E4bWyXGoan9xDbUOD\nXNoqlLm0dcfdvxlsHx7lNfIqr7xGbQtLfK4APsbJ3/hosP2Ws3yBPPfSf6W23Tv5e72W4RGQy0t8\nra6thiNasw0e6Tq6K+y6Zr2n8NSVX4hEkfMLkShyfiESRc4vRKLI+YVIlL7u9rfbwGotbDt2igda\n2Fo4WKEa2dkslvjnmjf4rux4JCBo6VJ48KNVvoM9uYfn4jv2Ci939cYpXuZr7vwZats7uTPYvrjE\nA4WO/pznsysVeXmt5UjOuiLCc3XTIFdaLq1EAlmG+ThmT/NgoR37bg+23/+Pf4f2WV/nasrx5/+W\n2lp1srgBWJa7Wr4SnhNf53NVXw8fy9sK7BFCbICcX4hEkfMLkShyfiESRc4vRKLI+YVIlF7Kde0B\n8KcAdqBTnuuQu3/DzMYAfB/AXnRKdn3S3edjr+VwNElponKRV/mukmCQdpNLK6s1Lh2urUfytxV5\nKazzF2eC7SfPh8t4AUC1yiWqM2+cpra1pXAwEwA0G1xim5+7GGzfuZ3n2/NI9eR2kwfA1Fp8Hhen\nw+fWmuHBKpcuzVHbYGmM2o7/ipdEm1sMr5F9e/l8fOCee6jt1KvPUVsjknPPmzywx4xIfW3ep+2s\nxFokou0qernyNwF8wd3vAHA/gD8yszsAPArgKXc/AOCp7t9CiHcJGzq/u0+5+3Pdx0sAjgCYBPAg\ngMe7T3scwEM3apBCiOvP2/rNb2Z7AdwD4BkAO9z9cl7k8+j8LBBCvEvo2fnNrArghwA+7+5v+XHj\nnWThwfsKzewRMztsZodXVvlvSyFEf+nJ+c0sj47jf8fdf9RtnjazXV37LgDB3TB3P+TuB9394ECl\nr6EEQogIGzq/dfICfRvAEXf/2hWmJwBcLpXyMICfXP/hCSFuFL1cij8I4DMAXjKzF7ptXwTwFQA/\nMLPPAngTwCc3eqFyqYg77tgbtGVax2i/NYRlr/UMl0IydW4bWOG555YikWXPPP3nYUODH6uYK1Pb\nckwaApfzBkv8NRvkvGcvztI+GefyUL3G5dQd28eprVIMlyLLNZlEBVQrQ9SWzxepbXWeS4SNWng+\nXvl/T9E+89Mnqa06xPMFzl8Iy6wAkI+4WjYXvgazMl4depf0GBs6v7v/DQAW5/qRTY9ACLEl6A4/\nIRJFzi9Eosj5hUgUOb8QiSLnFyJR+lyuK4dxIg9VJo7SflOL4YSVzQEud+QyvDzVwBqXaxZmTlJb\noRaW2IYKPHKv1ebSVik2+x5J+EikIQDIElOrye+ujNkyGT4OD9/UCQC4cCEc6bh3F78L/L138mi6\nS2v8vV6YPU9ttdlwMs7TR3kk4HqdRx5un+Dy5nCkfJm1+DpAhpxbpKxcux0W4HpP36krvxDJIucX\nIlHk/EIkipxfiESR8wuRKHJ+IRKlz7X6HGur4SiryiCXUFanw7XY6s4lqm0TXH4rFflpnzu3RG0X\nToTr3RWdSzwjw1yu2buLJy0dKJWoLZvhn9lNItstL6/SPsVYlKBz8SgXiVi87a7fDLY317iMVixw\neXZt7iS11Zd4VF+GSK1DRb52Bop8HN7gUY7bxrdT2+oSj/hbqYXfm1KRr4GMhaMc7W1cz3XlFyJR\n5PxCJIqcX4hEkfMLkShyfiESpa+7/bW1Bo4fCQdh7N07SfsdKIWDRM5e4NXBrMFzvtkYP+2JUV6u\na7kaVgIWp/kO9uI8L7tVdF7u6sAtN1MbK+8EAGur4bGsLPNd6nKVqw63v+8OahuY2EVtq+3w/E/u\nvon2mTkTVnUAYGmel0TbESlFtrgYnv+BSPmsRpMrI80Wz6u32uDroJ3l67FNVKsWUQEAoEKCu4wl\n3AugK78QiSLnFyJR5PxCJIqcX4hEkfMLkShyfiESZUOpz8z2APhTdEpwO4BD7v4NM/sygD8AcFmD\n+aK7/zT2Ws1mC/PnLwVt9999G+2XOXBnsL0xx/OwLU5zSabOFRRaZgoA7rpld7A9dzOfxvUlXpJr\nfS0cKAQA56emqS2X42NsEwWrHMkvl43IUMuLfIwzkfJU7XY4IGh5907a58TR49Q2UhyktsYalzHX\nSPk1A5/DZpPrZUuLPPCLBVUBgLW5POut5WD7QIlL2dsnDgTbc29DvO/lqU0AX3D358xsEMCzZvZk\n1/Z1d/+PvR9OCPFOoZdafVMAprqPl8zsCAB+R44Q4l3B2/rNb2Z7AdwD4Jlu0+fM7EUze8zM+G1i\nQoh3HD07v5lVAfwQwOfdfRHANwHsB3A3Ot8Mvkr6PWJmh83s8MparOSwEKKf9OT8ZpZHx/G/4+4/\nAgB3n3b3lru3AXwLwH2hvu5+yN0PuvvBgTLfZBFC9JcNnd/MDMC3ARxx969d0X5lVMcnALx8/Ycn\nhLhR9LLb/0EAnwHwkpm90G37IoBPm9nd6Mh/JwH84UYv1Gy0MXshrLOdPzdD++3eHc7vtz8SIXb0\nNV7Cqb3MSz8VI5+HVAaM5BIcneASVb3N5beFhYik1ODjHx8Lb714hn/rmpmZpbbZiJw3OMBzzG3f\nFh7Hm796no/jbFgGBoDF/DC1zc/xZZwrhn9qtsDnsLYeifiLVN1aXubroJDl+vL2beFowP27+fwO\nT4bzDBbyvYf19bLb/zcAQq8Y1fSFEO9sdIefEIki5xciUeT8QiSKnF+IRJHzC5EofU3guVZr4uVj\n4USMxeIR2u+hf/Jbwfab9/Mkl2enuVRWr3MppxApQdVshmUjZ6F0AOprXFJaXubJPfM5Hmk3NMTl\nQ8uE39LlRS41tRu8JJdb5Nwa/I7NC7Nh+dDavE8uz4+1sMal20x+hNryzfD1LaJ8RqPz1ut8XZWr\nfB7Hd3AJbrQS1g8LRT4fQ6PhE8iSxJ4hdOUXIlHk/EIkipxfiESR8wuRKHJ+IRJFzi9EovS3Vl+9\niWNnwkkJF+Z4ssK77w0nKxys8Ki40xe5jDYYkcoq2UhyzEY4UWRMGlq4xBN4tmu8364dQ9SWi3xm\nN9fDEWJe53UBjStU8GBMV4d6g0tRuWI46qwYmd98nsuAhYjkmCmEjwUAxWJYBsxm+Xm1wZOnjmzj\nYxwc4e/nyDh/z4ZInotSpCZjrhR2XdXqE0JsiJxfiESR8wuRKHJ+IRJFzi9Eosj5hUiUvkp9uWwG\n48NEnmvxaKmllXBix+NHz9E+T/+fE9T23jvDNfcAoLRvO7UVPSw3Lc3zxJP1dS4NjY1VqS1f5m9N\nIyIRZojqVRnicphHEk+6c+3IMlwjzJFIRxYZCQADBZ6kM2sValtb4bJusxWWOKtVLqONTITlUgCo\nDvHrZTWS0LRY4fUEiywSb52f8/JyWB5stXvX+nTlFyJR5PxCJIqcX4hEkfMLkShyfiESZcPdfjMr\nAXgaQLH7/D9z9y+Z2T4A3wMwDuBZAJ9x90gxI6CQy2LPWDhgZajMA1l2Du8Itp85+jrtszDLc9a9\neewMtQ21+U7v6GB4N3eNBNMAQK7Id4Bbq8vUtk6UBQBoZXlgUoPk8DPjn/OFPF8GrcjuvIPv9jfr\npF8kiMgyfPlkc3y3vFzgQUsjY+H20XF+XsNcdEB1IDJXdZ6vMVZibYXs3C9d4Hkci0Qci5UTu5pe\nrvw1AL/r7h9Apxz3A2Z2P4A/BvB1d78VwDyAz/Z+WCHEVrOh83uHy5eofPefA/hdAH/WbX8cwEM3\nZIRCiBtCT7/5zSzbrdA7A+BJAMcBXHL/u/K0ZwBM3pghCiFuBD05v7u33P1uALsB3Afg9l4PYGaP\nmNlhMztca/LfsUKI/vK2dvvd/RKAvwbwDwGMmNnl3Y/dAM6SPofc/aC7Hyzm+C2VQoj+sqHzm9k2\nMxvpPi4D+D0AR9D5EPhn3ac9DOAnN2qQQojrTy+BPbsAPG5mWXQ+LH7g7n9uZq8C+J6Z/XsAzwP4\n9kYvVCqV8N7bwvn4JnfxfHw3778r2L4YCXz4CI+1wcoqDwQZHucyWqkcDo5pRYI26pHAmHKeB9QM\nVbj0udzmElDLwmMsR4JOqiV+DWhFfqrV61xXKpXDx8vEykkZl8OyOX6s8gCfx+Hx8PhHxrg8OFCO\njLHNv71eusjXweoc1zhr7fFge6PA3+dcPtzHrfdYvQ2f6e4vArgn0H4Cnd//Qoh3IbrDT4hEkfML\nkShyfiESRc4vRKLI+YVIFHOPhFld74OZXQDwZvfPCQAX+3ZwjsbxVjSOt/JuG8fN7r6tlxfsq/O/\n5cBmh9394JYcXOPQODQOfe0XIlXk/EIkylY6/6EtPPaVaBxvReN4K39vx7Flv/mFEFuLvvYLkShb\n4vxm9oCZ/crMXjezR7diDN1xnDSzl8zsBTM73MfjPmZmM2b28hVtY2b2pJkd6/4/ukXj+LKZne3O\nyQtm9rE+jGOPmf21mb1qZq+Y2b/qtvd1TiLj6OucmFnJzH5uZr/sjuPfddv3mdkzXb/5vhkJ4ewV\nd+/rPwBZdNKA3QKgAOCXAO7o9zi6YzkJYGILjvvbAO4F8PIVbf8BwKPdx48C+OMtGseXAfzrPs/H\nLgD3dh8PAjgK4I5+z0lkHH2dEwAGoNp9nAfwDID7AfwAwKe67f8FwL/czHG24sp/H4DX3f2Ed1J9\nfw/Ag1swji3D3Z8GMHdV84PoJEIF+pQQlYyj77j7lLs/1328hE6ymEn0eU4i4+gr3uGGJ83dCuef\nBHD6ir+3MvmnA/hLM3vWzB7ZojFcZoe7T3UfnwcQLlbQHz5nZi92fxbc8J8fV2Jme9HJH/EMtnBO\nrhoH0Oc56UfS3NQ3/D7k7vcC+H0Af2Rmv73VAwI6n/yIlre4oXwTwH50ajRMAfhqvw5sZlUAPwTw\neXdfvNLWzzkJjKPvc+KbSJrbK1vh/GcB7Lnib5r880bj7me7/88A+DG2NjPRtJntAoDu/zNbMQh3\nn+4uvDaAb6FPc2JmeXQc7jvu/qNuc9/nJDSOrZqT7rHfdtLcXtkK5/8FgAPdncsCgE8BeKLfgzCz\nATMbvPwYwEcBvBzvdUN5Ap1EqMAWJkS97GxdPoE+zImZGTo5II+4+9euMPV1Ttg4+j0nfUua268d\nzKt2Mz+Gzk7qcQD/ZovGcAs6SsMvAbzSz3EA+C46Xx8b6Px2+yw6NQ+fAnAMwF8BGNuicfx3AC8B\neBEd59vVh3F8CJ2v9C8CeKH772P9npPIOPo6JwDej05S3BfR+aD5t1es2Z8DeB3A/wRQ3MxxdIef\nEImS+oafEMki5xciUeT8QiSKnF+IRJHzC5Eocn4hEkXOL0SiyPmFSJT/D0b9U6k8PVnzAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1bd3b8c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.rot90(v.T, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 s, sys: 1.19 s, total: 26 s\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Xa = []\n",
    "Ya = []\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    x = X[i]\n",
    "    x = torch.from_numpy(x)\n",
    "    x = to_tensor(to_img(x)).numpy()\n",
    "    v = torch.from_numpy(x)\n",
    "    v = to_tensor(flip(to_img(v))).numpy()\n",
    "    \n",
    "    Xa.append(x.tolist())\n",
    "    Ya.append(Y[i].tolist())\n",
    "    \n",
    "#     if np.array_equal(v, x): continue\n",
    "    continue\n",
    "    v = torch.from_numpy(x)\n",
    "    v = to_tensor(flip((central_crop(crop(to_img(v)))))).numpy()\n",
    "    Xa.append(v.tolist())\n",
    "    Ya.append(Y[i].tolist())\n",
    "\n",
    "Xa = np.array(Xa)\n",
    "Ya = np.array(Ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 200 ms, total: 3.06 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Xta = []\n",
    "Yta = []\n",
    "for i in range(Xt.shape[0]):\n",
    "    x = Xt[i]\n",
    "    x = torch.from_numpy(x)\n",
    "    x = to_tensor(to_img(x)).numpy()\n",
    "    Xta.append(x.tolist())\n",
    "    Yta.append(Y[i].tolist())\n",
    "Xta = np.array(Xta)\n",
    "Yta = np.array(Yta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3, 32, 32), (50000, 3, 32, 32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((50000,), (50000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.47336301124422492, 0.40567556225505541)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4.5, 6.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xa.shape, X.shape\n",
    "Ya.shape, Y.shape\n",
    "Xa.mean(), Xa[0].mean()\n",
    "Ya.mean(), Y[0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):  \n",
    "    def __init__(self,batch_size = 10, drop_probability = 0.5):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        in_size = 3        \n",
    "        self.hidden_layer1_size = 64\n",
    "        self.hidden_layer2_size = 128\n",
    "        self.hidden_fc_layer_size = 5 * 5 * self.hidden_layer2_size\n",
    "        \n",
    "        self.layer1 = nn.Sequential( \\\n",
    "                                    nn.Conv2d(in_size, self.hidden_layer1_size, 5),\n",
    "                                    nn.Dropout2d(drop_probability),\n",
    "                                    nn.BatchNorm2d(self.hidden_layer1_size),\n",
    "                                    nn.PReLU(),\n",
    "                                    nn.MaxPool2d(2, stride=2)\n",
    "                                   )\n",
    "        self.layer2 = nn.Sequential( \\\n",
    "                                    nn.Conv2d(self.hidden_layer1_size, self.hidden_layer2_size, 5),\n",
    "                                    nn.Dropout2d(drop_probability),\n",
    "                                    nn.BatchNorm2d(self.hidden_layer2_size),\n",
    "                                    nn.PReLU(),\n",
    "                                    nn.MaxPool2d(2, stride=2)\n",
    "                                   )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential( \\\n",
    "                                      nn.Linear(self.hidden_fc_layer_size, 2 * self.hidden_fc_layer_size // 3),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout2d(),\n",
    "                                      nn.Linear(2 * self.hidden_fc_layer_size // 3, 3 * batch_size // 2),\n",
    "                                      nn.PReLU(),\n",
    "                                      nn.Dropout2d(),\n",
    "                                      nn.Linear(3 * batch_size // 2, batch_size),\n",
    "                                      nn.ReLU()\n",
    "                                     )\n",
    "        \n",
    "        self.train_epoch_loss_list = []\n",
    "        self.test_epoch_loss_list = []\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        print (x.data.size())\n",
    "        x = self.fc_layer(x)\n",
    "        print (x.data.size())\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 40\n",
    "batch_size = 1000\n",
    "drop_probability = 0.3\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net (\n",
       "  (layer1): Sequential (\n",
       "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): Dropout2d (p=0.3)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (3): PReLU (1)\n",
       "    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layer2): Sequential (\n",
       "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): Dropout2d (p=0.3)\n",
       "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (3): PReLU (1)\n",
       "    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (fc_layer): Sequential (\n",
       "    (0): Linear (3200 -> 2133)\n",
       "    (1): ReLU ()\n",
       "    (2): Dropout2d (p=0.5)\n",
       "    (3): Linear (2133 -> 1500)\n",
       "    (4): PReLU (1)\n",
       "    (5): Dropout2d (p=0.5)\n",
       "    (6): Linear (1500 -> 1000)\n",
       "    (7): ReLU ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(batch_size=batch_size, drop_probability=drop_probability).cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/40\n",
      "torch.Size([1000, 128, 5, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:66",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-e89cf17be0cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_contiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmm\u001b[0;34m(self, matrix)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mAddmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:66"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_epoch_loss_list = []\n",
    "test_epoch_loss_list = []\n",
    "for epoch in range(n_epoch):\n",
    "    train_epoch_loss = 0\n",
    "    test_epoch_loss = 0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    print ('\\nEpoch %s/%s' %(epoch+1,n_epoch))\n",
    "    Xperm = np.random.permutation(Xa.shape[0])\n",
    "    net.train(True)\n",
    "    for b in tqdm(range(Xa.shape[0]//batch_size)):\n",
    "        batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "        \n",
    "        x = Variable(torch.Tensor(Xa[batch_idxs].tolist())).cuda()\n",
    "        y = Variable(torch.LongTensor(Ya[batch_idxs].tolist())).cuda()\n",
    "        \n",
    "        y_hat = net(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.data[0]\n",
    "        \n",
    "        _, preds = torch.max(y_hat.data, 1)\n",
    "        running_corrects += torch.sum(preds == y.data)\n",
    "    \n",
    "    print (\"Epoch accuracy %s\" %(running_corrects/Ya.shape[0]))\n",
    "    ## learn test\n",
    "#     Xperm = np.random.permutation(Xt.shape[0])\n",
    "#     net.train(False)\n",
    "#     for b in range(Xta.shape[0]//batch_size):\n",
    "#         batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "#         x = Variable(torch.Tensor(Xta[batch_idxs].tolist()),volatile = True).cuda()\n",
    "#         y = Variable(torch.LongTensor(Yta[batch_idxs]),volatile = True).cuda()\n",
    "\n",
    "#         y_hat = net(x)\n",
    "#         loss = criterion(y_hat, y)\n",
    "#         test_epoch_loss += loss.data[0]\n",
    "    \n",
    "#     # save loss and lr for current epoch\n",
    "#     train_epoch_loss_list.append(train_epoch_loss)\n",
    "#     test_epoch_loss_list.append(test_epoch_loss)\n",
    "#     print (\"Epoch loss \\ntrain %s \\ntest %s\\n\" %(train_epoch_loss_list[-1], test_epoch_loss_list[-1]))\n",
    "    \n",
    "net.train_epoch_loss_list = train_epoch_loss_list\n",
    "net.test_epoch_loss_list = test_epoch_loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"Min values and epoch\\ntrain: %s\\ntest: %s\" \\\n",
    "       %(np.array(train_epoch_loss_list).min(), np.array(test_epoch_loss_list).min()) )\n",
    "train_loss, = plt.plot(train_epoch_loss_list, 'g-',linewidth = 1, label='Train')\n",
    "test_loss, = plt.plot(test_epoch_loss_list, 'b-',linewidth = 1, label = \"Test\")\n",
    "plt.legend(handles=[train_loss, test_loss])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save parameters to pickle file\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_parametrs = net.state_dict()\n",
    "with open('./result_nets.pkl','wb') as f:\n",
    "    pickle.dump(net_parametrs,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load parameters from pickle file\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result_nets.pkl','rb') as f:\n",
    "    result_nets = pickle.load(f)\n",
    "net.load_state_dict(result_nets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn test data\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train(False)\n",
    "\n",
    "batch_size = 1000\n",
    "loss_acc = 0\n",
    "Xperm = np.random.permutation(Xt.shape[0])\n",
    "loss_fn = torch.nn.CrossEntropyLoss().cuda()\n",
    "y_hat = []\n",
    "for b in range(Xt.shape[0]//batch_size):\n",
    "    batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "    x = Variable(torch.Tensor(Xt[batch_idxs].tolist()),volatile = True).cuda()\n",
    "    y = Variable(torch.LongTensor(Yt[batch_idxs]),volatile = True).cuda()\n",
    "    \n",
    "    \n",
    "    y_hat.append(net(x))\n",
    "    loss = loss_fn(y_hat[b], y)\n",
    "    loss_acc +=loss.data[0]\n",
    "\n",
    "print (loss_acc / (Xt.shape[0]//batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save result of test\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pandas.DataFrame()\n",
    "d['id'] = range(len(Yt))\n",
    "res = y_hat\n",
    "if type(y_hat) == list:\n",
    "    res = y_hat[0].data.cpu().numpy()\n",
    "    for i in range(1, len(y_hat)):\n",
    "        res = np.vstack((res, y_hat[i].cpu().data.numpy()))\n",
    "        \n",
    "for i in range(10):\n",
    "    d['c%s' % i] = np.exp(res[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('./ground.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classes:**\n",
    "======\n",
    "1. airplane \n",
    "2. automobile\n",
    "3. bird\n",
    "4. cat\n",
    "5. deer \n",
    "6. dog\n",
    "7. frog\n",
    "8. horse\n",
    "9. ship\n",
    "10. truck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "    def __init__(self):\n",
    "        self.lr0 = 0.0001\n",
    "        self.epoch = 0\n",
    "        self.punch = 0.0003\n",
    "        self.lr = 0.0001\n",
    "        self.base = 0.5\n",
    "    \n",
    "    @property\n",
    "    def rate(self):\n",
    "        return self.epoch // 15\n",
    "    \n",
    "    def make_punch(self):\n",
    "        self.lr = self.punch\n",
    "        self.epoch = 0\n",
    "        \n",
    "    @property\n",
    "    def updated_lr(self):\n",
    "        return self.lr0 * ( self.base **  self.rate )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
