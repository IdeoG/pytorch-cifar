{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "import copy\n",
    "import pandas\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import *\n",
    "import torchvision\n",
    "import pickle\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for b in range(1, 6):\n",
    "    D = unpickle('./cifar-10-batches-py/data_batch_%s' % b)\n",
    "    X.append( D[b'data'].reshape((-1, 3, 32, 32)).astype('uint8') )\n",
    "    Y.append( np.array(D[b'labels']))\n",
    "    names = [x.decode('utf-8') for x in D]\n",
    "\n",
    "X = np.vstack(X)\n",
    "Y = np.hstack(Y).astype('int')\n",
    "\n",
    "D = unpickle('./cifar-10-batches-py/test_batch')\n",
    "Xt = D[b'data'].reshape((-1, 3, 32, 32)).astype('uint8')\n",
    "Yt = np.array(D[b'labels']).astype('int')\n",
    "Lt = D[b'filenames']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_img = ToPILImage()\n",
    "resized_crop = RandomResizedCrop(32)\n",
    "crop = RandomCrop([32,32])\n",
    "central_crop = CenterCrop([32,32])\n",
    "flip = RandomHorizontalFlip()\n",
    "color = ColorJitter(brightness=0.5,contrast=0,saturation=0)\n",
    "gray = Grayscale()\n",
    "to_tensor = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X[0]\n",
    "x = torch.from_numpy(x)\n",
    "x = to_tensor(to_img(x)).numpy()\n",
    "v = torch.from_numpy(x)\n",
    "v = color(to_img(v))\n",
    "v = to_tensor(v).numpy()\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show image\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5b8a77fdd8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfiESRc4vRKLI+YVIlP8Dfw9Sr1G8vSsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b8a7ca7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.rot90(x.T, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5b8a6c3f98>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b8a7ca0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.rot90(v.T, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 s, sys: 1.19 s, total: 26 s\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Xa = []\n",
    "Ya = []\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    x = X[i]\n",
    "    x = torch.from_numpy(x)\n",
    "    x = to_tensor(to_img(x)).numpy()\n",
    "    v = torch.from_numpy(x)\n",
    "    v = to_tensor(flip(to_img(v))).numpy()\n",
    "    \n",
    "    Xa.append(x.tolist())\n",
    "    Ya.append(Y[i].tolist())\n",
    "    \n",
    "#     if np.array_equal(v, x): continue\n",
    "    continue\n",
    "    v = torch.from_numpy(x)\n",
    "    v = to_tensor(flip((central_crop(crop(to_img(v)))))).numpy()\n",
    "    Xa.append(v.tolist())\n",
    "    Ya.append(Y[i].tolist())\n",
    "\n",
    "X = np.array(Xa)\n",
    "Y = np.array(Ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 200 ms, total: 3.06 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Xta = []\n",
    "Yta = []\n",
    "for i in range(Xt.shape[0]):\n",
    "    x = Xt[i]\n",
    "    x = torch.from_numpy(x)\n",
    "    x = to_tensor(to_img(x)).numpy()\n",
    "    Xta.append(x.tolist())\n",
    "    Yta.append(Y[i].tolist())\n",
    "Xa = np.array(Xta)\n",
    "Ya = np.array(Yta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-685dd8229747>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.shape, Y.shape\n",
    "X.mean(), Xt[0].mean()\n",
    "X.std(), Xt[0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):  \n",
    "    def __init__(self,batch_size = 10, drop_probability = 0.5):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        in_size = 3        \n",
    "        self.hidden_layer1_size = 64\n",
    "        self.hidden_layer2_size = 128\n",
    "        self.hidden_fc_layer_size = 5 * 5 * self.hidden_layer2_size\n",
    "        \n",
    "        self.layer1 = nn.Sequential( \\\n",
    "                                    nn.Conv2d(in_size, self.hidden_layer1_size, 5),\n",
    "                                    nn.Dropout2d(drop_probability),\n",
    "                                    nn.BatchNorm2d(self.hidden_layer1_size),\n",
    "                                    nn.PReLU(),\n",
    "                                    nn.MaxPool2d(2, stride=2)\n",
    "                                   )\n",
    "        self.layer2 = nn.Sequential( \\\n",
    "                                    nn.Conv2d(self.hidden_layer1_size, self.hidden_layer2_size, 5),\n",
    "                                    nn.Dropout2d(drop_probability),\n",
    "                                    nn.BatchNorm2d(self.hidden_layer2_size),\n",
    "                                    nn.PReLU(),\n",
    "                                    nn.MaxPool2d(2, stride=2)\n",
    "                                   )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential( \\\n",
    "                                      nn.Linear(self.hidden_fc_layer_size, 2 * self.hidden_fc_layer_size // 3),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout2d(),\n",
    "                                      nn.Linear(2 * self.hidden_fc_layer_size // 3, 3 * batch_size // 2),\n",
    "                                      nn.PReLU(),\n",
    "                                      nn.Dropout2d(),\n",
    "                                      nn.Linear(3 * batch_size // 2, batch_size),\n",
    "                                      nn.ReLU()\n",
    "                                     )\n",
    "        \n",
    "        self.train_epoch_loss_list = []\n",
    "        self.test_epoch_loss_list = []\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.fc_layer(x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 40\n",
    "batch_size = 1000\n",
    "drop_probability = 0.3\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net (\n",
       "  (layer1): Sequential (\n",
       "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): Dropout2d (p=0.3)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (3): PReLU (1)\n",
       "    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layer2): Sequential (\n",
       "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): Dropout2d (p=0.3)\n",
       "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (3): PReLU (1)\n",
       "    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (fc_layer): Sequential (\n",
       "    (0): Linear (3200 -> 2133)\n",
       "    (1): ReLU ()\n",
       "    (2): Dropout2d (p=0.5)\n",
       "    (3): Linear (2133 -> 1500)\n",
       "    (4): PReLU (1)\n",
       "    (5): Dropout2d (p=0.5)\n",
       "    (6): Linear (1500 -> 1000)\n",
       "    (7): ReLU ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(batch_size=batch_size, drop_probability=drop_probability).cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/40\n",
      "torch.Size([1000, 128, 5, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:66",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-49947053391b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_contiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmm\u001b[0;34m(self, matrix)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mAddmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:66"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_epoch_loss_list = []\n",
    "test_epoch_loss_list = []\n",
    "for epoch in range(n_epoch):\n",
    "    train_epoch_loss = 0\n",
    "    test_epoch_loss = 0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    print ('\\nEpoch %s/%s' %(epoch+1,n_epoch))\n",
    "    Xperm = np.random.permutation(Xa.shape[0])\n",
    "    net.train(True)\n",
    "    for b in tqdm(range(Xa.shape[0]//batch_size)):\n",
    "        batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "        \n",
    "        x = Variable(torch.Tensor(Xa[batch_idxs].tolist())).cuda()\n",
    "        y = Variable(torch.LongTensor(Ya[batch_idxs].tolist())).cuda()\n",
    "        \n",
    "        y_hat = net(x)\n",
    "        print (y.size(), y_hat.size())\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.data[0]\n",
    "        \n",
    "#         _, preds = torch.max(y_hat.data, 1)\n",
    "#         running_corrects += torch.sum(preds == y.data)\n",
    "    \n",
    "#     print (\"Epoch accuracy %s\" %(running_corrects/Ya.shape[0]))\n",
    "    ## learn test\n",
    "#     Xperm = np.random.permutation(Xt.shape[0])\n",
    "#     net.train(False)\n",
    "#     for b in range(Xta.shape[0]//batch_size):\n",
    "#         batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "#         x = Variable(torch.Tensor(Xta[batch_idxs].tolist()),volatile = True).cuda()\n",
    "#         y = Variable(torch.LongTensor(Yta[batch_idxs]),volatile = True).cuda()\n",
    "\n",
    "#         y_hat = net(x)\n",
    "#         loss = criterion(y_hat, y)\n",
    "#         test_epoch_loss += loss.data[0]\n",
    "    \n",
    "#     # save loss and lr for current epoch\n",
    "#     train_epoch_loss_list.append(train_epoch_loss)\n",
    "#     test_epoch_loss_list.append(test_epoch_loss)\n",
    "#     print (\"Epoch loss \\ntrain %s \\ntest %s\\n\" %(train_epoch_loss_list[-1], test_epoch_loss_list[-1]))\n",
    "    \n",
    "net.train_epoch_loss_list = train_epoch_loss_list\n",
    "net.test_epoch_loss_list = test_epoch_loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"Min values and epoch\\ntrain: %s\\ntest: %s\" \\\n",
    "       %(np.array(train_epoch_loss_list).min(), np.array(test_epoch_loss_list).min()) )\n",
    "train_loss, = plt.plot(train_epoch_loss_list, 'g-',linewidth = 1, label='Train')\n",
    "test_loss, = plt.plot(test_epoch_loss_list, 'b-',linewidth = 1, label = \"Test\")\n",
    "plt.legend(handles=[train_loss, test_loss])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save parameters to pickle file\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_parametrs = net.state_dict()\n",
    "with open('./result_nets.pkl','wb') as f:\n",
    "    pickle.dump(net_parametrs,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load parameters from pickle file\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result_nets.pkl','rb') as f:\n",
    "    result_nets = pickle.load(f)\n",
    "net.load_state_dict(result_nets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn test data\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train(False)\n",
    "\n",
    "batch_size = 1000\n",
    "loss_acc = 0\n",
    "Xperm = np.random.permutation(Xt.shape[0])\n",
    "loss_fn = torch.nn.CrossEntropyLoss().cuda()\n",
    "y_hat = []\n",
    "for b in range(Xt.shape[0]//batch_size):\n",
    "    batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "    x = Variable(torch.Tensor(Xt[batch_idxs].tolist()),volatile = True).cuda()\n",
    "    y = Variable(torch.LongTensor(Yt[batch_idxs]),volatile = True).cuda()\n",
    "    \n",
    "    \n",
    "    y_hat.append(net(x))\n",
    "    loss = loss_fn(y_hat[b], y)\n",
    "    loss_acc +=loss.data[0]\n",
    "\n",
    "print (loss_acc / (Xt.shape[0]//batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save result of test\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pandas.DataFrame()\n",
    "d['id'] = range(len(Yt))\n",
    "res = y_hat\n",
    "if type(y_hat) == list:\n",
    "    res = y_hat[0].data.cpu().numpy()\n",
    "    for i in range(1, len(y_hat)):\n",
    "        res = np.vstack((res, y_hat[i].cpu().data.numpy()))\n",
    "        \n",
    "for i in range(10):\n",
    "    d['c%s' % i] = np.exp(res[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('./ground.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classes:**\n",
    "======\n",
    "1. airplane \n",
    "2. automobile\n",
    "3. bird\n",
    "4. cat\n",
    "5. deer \n",
    "6. dog\n",
    "7. frog\n",
    "8. horse\n",
    "9. ship\n",
    "10. truck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "    def __init__(self):\n",
    "        self.lr0 = 0.0001\n",
    "        self.epoch = 0\n",
    "        self.punch = 0.0003\n",
    "        self.lr = 0.0001\n",
    "        self.base = 0.5\n",
    "    \n",
    "    @property\n",
    "    def rate(self):\n",
    "        return self.epoch // 15\n",
    "    \n",
    "    def make_punch(self):\n",
    "        self.lr = self.punch\n",
    "        self.epoch = 0\n",
    "        \n",
    "    @property\n",
    "    def updated_lr(self):\n",
    "        return self.lr0 * ( self.base **  self.rate )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
