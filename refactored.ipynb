{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for b in range(1, 6):\n",
    "    D = unpickle('./cifar-10-batches-py/data_batch_%s' % b)\n",
    "    X.append( D[b'data'].reshape((-1, 3, 32, 32)).astype('uint8') )\n",
    "    Y.append( np.array(D[b'labels']))\n",
    "    names = [x.decode('utf-8') for x in D]\n",
    "\n",
    "X = np.vstack(X)\n",
    "Y = np.hstack(Y).astype('int')\n",
    "\n",
    "D = unpickle('./cifar-10-batches-py/test_batch')\n",
    "Xt = D[b'data'].reshape((-1, 3, 32, 32)).astype('uint8')\n",
    "Yt = np.array(D[b'labels']).astype('int')\n",
    "Lt = D[b'filenames']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "Xa = []\n",
    "Ya = []\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    x = X[i]\n",
    "    x = torch.from_numpy(x)\n",
    "    x = to_tensor(to_img(x)).numpy()\n",
    "    \n",
    "    Xa.append(x.tolist())\n",
    "    Ya.append(Y[i].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmentation**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "to_img = transforms.ToPILImage()\n",
    "resized_crop = transforms.RandomResizedCrop(32)\n",
    "crop = transforms.RandomCrop([32,32])\n",
    "central_crop = transforms.CenterCrop([32,32])\n",
    "flip = transforms.RandomHorizontalFlip()\n",
    "color = transforms.ColorJitter(brightness=0.5,contrast=0,saturation=0)\n",
    "gray = transforms.Grayscale()\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create model**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        dropout_parameter = 0.3\n",
    "        \n",
    "        input_size = 3        \n",
    "        hidden_layer1_size = 48\n",
    "        hidden_layer2_size = 96\n",
    "        self.hidden_fc_layer_size = 96 * 6 * 6\n",
    "        output_size = 10\n",
    "        \n",
    "        \n",
    "        self.input_norm = nn.BatchNorm2d(input_size)\n",
    "        \n",
    "        self.layer1 = nn.Sequential( \\\n",
    "                                    nn.Conv2d(in_channels=input_size, out_channels=hidden_layer1_size, kernel_size=3, padding=1, stride=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Conv2d(in_channels=hidden_layer1_size, out_channels=hidden_layer1_size, kernel_size=3, padding=0, stride=1),\n",
    "                                    nn.Dropout2d(dropout_parameter),\n",
    "                                    nn.BatchNorm2d(hidden_layer1_size),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2, stride = 2)\n",
    "                                   )\n",
    "        \n",
    "        self.layer2 = nn.Sequential( \\\n",
    "                                    nn.Conv2d(in_channels=hidden_layer1_size, out_channels=hidden_layer2_size, kernel_size=3, padding=1, stride=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Conv2d(in_channels=hidden_layer2_size, out_channels=hidden_layer2_size, kernel_size=3, padding=0, stride=1),\n",
    "                                    nn.Dropout2d(dropout_parameter),\n",
    "                                    nn.BatchNorm2d(hidden_layer2_size),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(2, stride = 2)\n",
    "                                   )\n",
    "        \n",
    "       \n",
    "        self.fc_layer = nn.Sequential( \\\n",
    "                                      nn.Linear(self.hidden_fc_layer_size, output_size * 100),\n",
    "                                      nn.Dropout2d(),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(output_size * 100, output_size * 100),\n",
    "                                      nn.Dropout2d(),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(output_size * 100, output_size)\n",
    "                                     )\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.input_norm(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(-1, self.hidden_fc_layer_size)\n",
    "        self.fc_layer(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparams**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "    def __init__(self):\n",
    "        self.lr = 0.1\n",
    "        self.lock = -4\n",
    "        self.logic = False\n",
    "        \n",
    "    def update(self, epoch, loss=None):\n",
    "        if epoch < 5:\n",
    "            self.lr = 0.1\n",
    "        elif epoch < 20:\n",
    "            self.lr = 0.01\n",
    "        elif epoch < 100:\n",
    "            self.lr = 0.001\n",
    "        else:\n",
    "            self.lr = 0.0001\n",
    "        \n",
    "        if loss is not None:\n",
    "            print (loss)\n",
    "            loss = np.array(loss)\n",
    "            '''make punch and let it rest for 5 iter'''\n",
    "            print(\"Last %s loss std %s and mean %s\" %(loss.shape,loss.std(),loss.mean()))\n",
    "            if (loss.std() < 0.4) and (hp.lock + 4 < epoch):\n",
    "                if self.logic: self.lr = 10 * self.lr\n",
    "                else: self.lr = self.lr / 10\n",
    "                self.lock = epoch\n",
    "                print(\"PUNCH!\")\n",
    "                self.logic = not self.logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learn the model**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net (\n",
       "  (input_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer1): Sequential (\n",
       "    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU ()\n",
       "    (2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): Dropout2d (p=0.3)\n",
       "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): ReLU ()\n",
       "    (6): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layer2): Sequential (\n",
       "    (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU ()\n",
       "    (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): Dropout2d (p=0.3)\n",
       "    (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): ReLU ()\n",
       "    (6): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (fc_layer): Sequential (\n",
       "    (0): Linear (3456 -> 1000)\n",
       "    (1): Dropout2d (p=0.5)\n",
       "    (2): ReLU ()\n",
       "    (3): Linear (1000 -> 1000)\n",
       "    (4): Dropout2d (p=0.5)\n",
       "    (5): ReLU ()\n",
       "    (6): Linear (1000 -> 10)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net().cuda()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hp = Hyperparams()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=hp.lr)\n",
    "\n",
    "train_epoch_loss_list = []\n",
    "test_epoch_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/160\n",
      "Epoch train accuracy 0.06564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/160 [00:20<55:04, 20.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.1001\n",
      "Epoch loss: train 262.0794870853424 and test: 34.86334276199341\n",
      "lr 0.1\n",
      "\n",
      "\n",
      "Epoch 2/160\n",
      "Epoch train accuracy 0.10456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 2/160 [00:39<52:34, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0966\n",
      "Epoch loss: train 164.0585629940033 and test: 30.44432306289673\n",
      "lr 0.1\n",
      "\n",
      "\n",
      "Epoch 3/160\n",
      "Epoch train accuracy 0.10762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/160 [00:58<51:15, 19.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0963\n",
      "Epoch loss: train 160.54601526260376 and test: 30.710731029510498\n",
      "lr 0.1\n",
      "\n",
      "\n",
      "Epoch 4/160\n",
      "Epoch train accuracy 0.10848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 4/160 [01:17<50:25, 19.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0931\n",
      "Epoch loss: train 159.17747020721436 and test: 30.489855527877808\n",
      "lr 0.1\n",
      "\n",
      "\n",
      "Epoch 5/160\n",
      "Epoch train accuracy 0.12212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 5/160 [01:36<49:49, 19.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0995\n",
      "Epoch loss: train 157.64793920516968 and test: 29.83544397354126\n",
      "lr 0.1\n",
      "\n",
      "[164.0585629940033, 160.54601526260376, 159.17747020721436, 157.64793920516968]\n",
      "Last (4,) loss std 2.36999975224 and mean 160.357496917\n",
      "\n",
      "Epoch 6/160\n",
      "Epoch train accuracy 0.13258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 6/160 [01:55<49:19, 19.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.1012\n",
      "Epoch loss: train 155.9716100692749 and test: 29.226439952850342\n",
      "lr 0.01\n",
      "\n",
      "[160.54601526260376, 159.17747020721436, 157.64793920516968, 155.9716100692749]\n",
      "Last (4,) loss std 1.70704472258 and mean 158.335758686\n",
      "\n",
      "Epoch 7/160\n",
      "Epoch train accuracy 0.13694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 7/160 [02:14<48:51, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0996\n",
      "Epoch loss: train 154.69183254241943 and test: 29.204413890838623\n",
      "lr 0.01\n",
      "\n",
      "[159.17747020721436, 157.64793920516968, 155.9716100692749, 154.69183254241943]\n",
      "Last (4,) loss std 1.69418907707 and mean 156.872213006\n",
      "\n",
      "Epoch 8/160\n",
      "Epoch train accuracy 0.13604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 8/160 [02:33<48:28, 19.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.1029\n",
      "Epoch loss: train 154.49271821975708 and test: 29.043790102005005\n",
      "lr 0.01\n",
      "\n",
      "[157.64793920516968, 155.9716100692749, 154.69183254241943, 154.49271821975708]\n",
      "Last (4,) loss std 1.2591828594 and mean 155.701025009\n",
      "\n",
      "Epoch 9/160\n",
      "Epoch train accuracy 0.13524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 9/160 [02:51<48:04, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0996\n",
      "Epoch loss: train 154.06782698631287 and test: 28.884506940841675\n",
      "lr 0.01\n",
      "\n",
      "[155.9716100692749, 154.69183254241943, 154.49271821975708, 154.06782698631287]\n",
      "Last (4,) loss std 0.709705205331 and mean 154.805996954\n",
      "\n",
      "Epoch 10/160\n",
      "Epoch train accuracy 0.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 10/160 [03:11<47:48, 19.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0968\n",
      "Epoch loss: train 154.1895046234131 and test: 28.92375349998474\n",
      "lr 0.01\n",
      "\n",
      "[154.69183254241943, 154.49271821975708, 154.06782698631287, 154.1895046234131]\n",
      "Last (4,) loss std 0.246048684003 and mean 154.360470593\n",
      "PUNCH!\n",
      "\n",
      "Epoch 11/160\n",
      "Epoch train accuracy 0.13858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 11/160 [03:30<47:27, 19.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0936\n",
      "Epoch loss: train 154.04535341262817 and test: 28.914010763168335\n",
      "lr 0.001\n",
      "\n",
      "[154.49271821975708, 154.06782698631287, 154.1895046234131, 154.04535341262817]\n",
      "Last (4,) loss std 0.178307388444 and mean 154.198850811\n",
      "\n",
      "Epoch 12/160\n",
      "Epoch train accuracy 0.13598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 12/160 [03:49<47:06, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.1011\n",
      "Epoch loss: train 153.65977001190186 and test: 28.7800874710083\n",
      "lr 0.01\n",
      "\n",
      "[154.06782698631287, 154.1895046234131, 154.04535341262817, 153.65977001190186]\n",
      "Last (4,) loss std 0.198729384523 and mean 153.990613759\n",
      "\n",
      "Epoch 13/160\n",
      "Epoch train accuracy 0.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 13/160 [04:07<46:42, 19.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0986\n",
      "Epoch loss: train 153.93299317359924 and test: 28.917562246322632\n",
      "lr 0.01\n",
      "\n",
      "[154.1895046234131, 154.04535341262817, 153.65977001190186, 153.93299317359924]\n",
      "Last (4,) loss std 0.194156305011 and mean 153.956905305\n",
      "\n",
      "Epoch 14/160\n",
      "Epoch train accuracy 0.13428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 14/160 [04:26<46:21, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0961\n",
      "Epoch loss: train 154.11234498023987 and test: 28.770448684692383\n",
      "lr 0.01\n",
      "\n",
      "[154.04535341262817, 153.65977001190186, 153.93299317359924, 154.11234498023987]\n",
      "Last (4,) loss std 0.172740651151 and mean 153.937615395\n",
      "\n",
      "Epoch 15/160\n",
      "Epoch train accuracy 0.13828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 15/160 [04:45<45:56, 19.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0978\n",
      "Epoch loss: train 153.50401306152344 and test: 28.95422101020813\n",
      "lr 0.01\n",
      "\n",
      "[153.65977001190186, 153.93299317359924, 154.11234498023987, 153.50401306152344]\n",
      "Last (4,) loss std 0.235848727482 and mean 153.802280307\n",
      "PUNCH!\n",
      "\n",
      "Epoch 16/160\n",
      "Epoch train accuracy 0.13786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 16/160 [05:04<45:41, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0983\n",
      "Epoch loss: train 153.52433609962463 and test: 28.69005584716797\n",
      "lr 0.1\n",
      "\n",
      "[153.93299317359924, 154.11234498023987, 153.50401306152344, 153.52433609962463]\n",
      "Last (4,) loss std 0.262133888035 and mean 153.768421829\n",
      "\n",
      "Epoch 17/160\n",
      "Epoch train accuracy 0.13634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 17/160 [05:24<45:33, 19.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.1017\n",
      "Epoch loss: train 154.64259338378906 and test: 28.998212575912476\n",
      "lr 0.01\n",
      "\n",
      "[154.11234498023987, 153.50401306152344, 153.52433609962463, 154.64259338378906]\n",
      "Last (4,) loss std 0.470655332103 and mean 153.945821881\n",
      "\n",
      "Epoch 18/160\n",
      "Epoch train accuracy 0.13612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 18/160 [05:44<45:21, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch test accuracy 0.0951\n",
      "Epoch loss: train 153.53926849365234 and test: 28.55550241470337\n",
      "lr 0.01\n",
      "\n",
      "[153.50401306152344, 153.52433609962463, 154.64259338378906, 153.53926849365234]\n",
      "Last (4,) loss std 0.485159076025 and mean 153.80255276\n",
      "\n",
      "Epoch 19/160\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epoch = 160\n",
    "batch_size = 1000\n",
    "for epoch in tqdm(range(n_epoch)):\n",
    "    if epoch < 5:\n",
    "        hp.update(epoch)\n",
    "    else:\n",
    "        hp.update(epoch,loss=train_epoch_loss_list[-4:])\n",
    "    train_epoch_loss = 0\n",
    "    test_epoch_loss = 0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    print ('\\nEpoch %s/%s' %(epoch+1,n_epoch))\n",
    "    Xperm = np.random.permutation(X.shape[0])\n",
    "    net.train(True)\n",
    "    for b in range(X.shape[0]//batch_size):\n",
    "        batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "        \n",
    "        x = Variable(torch.Tensor(X[batch_idxs].tolist())).cuda()\n",
    "        y = Variable(torch.LongTensor(Y[batch_idxs].tolist())).cuda()\n",
    "        \n",
    "        y_hat = net(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.data[0]\n",
    "        _, preds = torch.max(y_hat.data, 1)\n",
    "        running_corrects += torch.sum(preds == y.data)\n",
    "    print (\"Epoch train accuracy %s\" %(running_corrects/Y.shape[0]))\n",
    "    running_corrects= 0\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = hp.lr\n",
    "    \n",
    "    '''learn test'''\n",
    "    Xperm = np.random.permutation(Xt.shape[0])\n",
    "    net.train(False)\n",
    "    for b in range(Xt.shape[0]//batch_size):\n",
    "        batch_idxs = Xperm[b*batch_size:(b+1)*batch_size]\n",
    "        x = Variable(torch.Tensor(Xt[batch_idxs].tolist()),volatile = True).cuda()\n",
    "        y = Variable(torch.LongTensor(Yt[batch_idxs]),volatile = True).cuda()\n",
    "\n",
    "        y_hat = net(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        test_epoch_loss += loss.data[0]\n",
    "        running_corrects += torch.sum(preds == y.data)\n",
    "    print (\"Epoch test accuracy %s\" %(running_corrects/Yt.shape[0]))\n",
    "    \n",
    "    '''save loss for current epoch'''\n",
    "    train_epoch_loss_list.append(train_epoch_loss)\n",
    "    test_epoch_loss_list.append(test_epoch_loss)\n",
    "    print (\"Epoch loss: train %s and test: %s\\nlr %s\\n\" %(train_epoch_loss_list[-1], test_epoch_loss_list[-1], hp.lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot results**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Min values and epoch\\ntrain: %s\\ntest: %s\" \\\n",
    "       %(np.array(train_epoch_loss_list).min(), np.array(test_epoch_loss_list).min()) )\n",
    "train_loss, = plt.plot(train_epoch_loss_list, 'g-',linewidth = 1, label='Train')\n",
    "test_loss, = plt.plot(test_epoch_loss_list, 'b-',linewidth = 1, label = \"Test\")\n",
    "plt.legend(handles=[train_loss, test_loss])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
